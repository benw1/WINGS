#!/usr/bin/env python
"""
Contains the Input class definition

Please note that this module is private. The Input class is
available in the main ``wpipe`` namespace - use that instead.
"""
from .core import gc, os, glob, shutil, datetime, pd, si
from .core import make_yield_session_if_not_cached, make_query_rtn_upd, maintain_cache
from .core import initialize_args, wpipe_to_sqlintf_connection, in_session
from .core import clean_path, remove_path, split_path
from .proxies import ChildrenProxy
from .DPOwner import DPOwner

__all__ = ['Input']

CLASS_NAME = split_path(__file__)[1]
KEYID_ATTR = 'input_id'
UNIQ_ATTRS = getattr(si, CLASS_NAME).__UNIQ_ATTRS__
CLASS_LOW = CLASS_NAME.lower()


def _in_session(**local_kw):
    return in_session('_%s' % CLASS_LOW, **local_kw)


_check_in_cache = make_yield_session_if_not_cached(KEYID_ATTR, UNIQ_ATTRS, CLASS_LOW)

_query_return_and_update_cached_row = make_query_rtn_upd(CLASS_LOW, KEYID_ATTR, UNIQ_ATTRS)


class Input(DPOwner):
    """
        Represents a pipeline's input.

        Call signatures::

            Input(pipeline, path)
            Input(keyid)
            Input(_input)

        When __new__ is called, it queries the database for an existing
        row in the `inputs` table via `sqlintf` using the given signature.
        If the row exists, it retrieves its corresponding `sqlintf.Input`
        object, otherwise it creates a new row via a new `sqlintf.Input`
        instance. This `sqlintf.Input` object is then wrapped under the
        hidden attribute `Input._input` in the new instance of this `Input`
        class generated by __new__.

        In the latter case where a new row is created, 2 directories are
        made respectively in the directories input_root and config_root of
        the pipeline, both named after the input name. With the making of
        the sub-directory in the input_root of the pipeline, the classmethod
        _copy_data is called to copy all data located in the path given to
        the constructor parameter path over to that specific sub-directory.

        All inputs are uniquely identified by their pipeline and their name,
        which latter is determined by __new__ as the tail returned by
        os.path.split(path) of the path parameter, but alternatively, the
        constructor can take as sole argument either:
         - the primary key id of the corresponding `inputs` table row
         - the `sqlintf.Input` object interfacing that table row

        After the instantiation of __new__ is completed, the __init__ method
        calls the object method _verify_raws to construct the DataProduct
        objects for all data files located in rawspath, while moving to
        confpath all files corresponding to configuration files (i.e. with a
        '.conf' extension).

        Parameters
        ----------
        pipeline : Pipeline object
            Pipeline owning this input.
        path : string
            Path to the input file or directory of files.
        keyid : int
            Primary key id of the table row.
        _input : sqlintf.Input object exposing SQL interface
            Corresponding sqlintf object interfacing the table row.

        Attributes
        ----------
        parents : Pipeline object
            Points to attribute self.pipeline.
        name : string
            Name of the input.
        input_id : int
            Primary key id of the table row.
        timestamp : datetime.datetime object
            Timestamp of last access to table row.
        rawspath : string
            Path to the input directory specific to raw data files.
        confpath : string
            Path to the input directory specific to configuration files.
        pipeline_id : int
            Primary key id of the table row of parent pipeline.
        pipeline : Pipeline object
            Pipeline object corresponding to parent pipeline.
        targets : core.ChildrenProxy object
            List of Target objects owned by the input.
        dpowner_id : int
            Points to attribute input_id.
        rawdataproducts : list of DataProduct objects
            List of DataProduct objects owned by the input corresponding
            to raw data files.
        confdataproducts : list of DataProduct objects
            List of DataProduct objects owned by the input corresponding
            to configuration files.
        logdataproducts : list of DataProduct objects
            List of DataProduct objects owned by the input corresponding
            to logging files.
        procdataproducts : list of DataProduct objects
            List of DataProduct objects owned by the input corresponding
            to processed data files.
        dataproducts : core.ChildrenProxy object
            List of DataProduct objects owned by the input.

        Notes
        -----
        An Input object requires a Pipeline object to construct: it is notably
        recommended to use the method attach_inputs of that Pipeline object
        for constructing a collection of inputs associated to the pipeline.
        Nevertheless, one can manually construct an Input object calling the
        constructor with the parent Pipeline object and the path where to find
        the data in arguments.

        >>> my_input = wp.Input(my_pipe, path_to_data)

        An input can represents multiple targets: accordingly, the Input
        object can have as many Target objects associated to it using the
        object method target. This method has the same call signature as the
        Target object constructor without specifying the input parameter: that
        is basically by providing the name of the target if different from the
        input name, in which case the method can be called without argument.

        >>> # if name_of_target != my_input.name
        >>> new_target = my_input.target(name_of_target)
        >>> # else
        >>> new_target = my_input.target()
    """
    __cache__ = pd.DataFrame(columns=[KEYID_ATTR]+UNIQ_ATTRS+[CLASS_LOW])

    @classmethod
    def _check_in_cache(cls, kind, loc):
        return _check_in_cache(cls, kind, loc)

    @classmethod
    def _sqlintf_instance_argument(cls):
        if hasattr(cls, '_%s' % CLASS_LOW):
            for _session in cls._check_in_cache(kind='keyid',
                                                loc=getattr(cls, '_%s' % CLASS_LOW).get_id()):
                pass

    @classmethod
    def _clear_unused_cached_instances(cls):
        mask = cls.__cache__[CLASS_LOW].map(gc.get_referrers).map(len) == 1
        _ = cls.__cache__[CLASS_LOW][mask].map(lambda obj: delattr(getattr(obj, '_%s' % CLASS_LOW), '_wpipe_object'))
        _ = cls.__cache__[CLASS_LOW][mask].map(lambda obj: delattr(obj, '_%s' % CLASS_LOW))
        cls.__cache__.drop(mask[mask].index, inplace=True)

    @classmethod
    def _return_cached_instances(cls):
        return [getattr(obj, '_%s' % CLASS_LOW) for obj in cls.__cache__[CLASS_LOW]]

    def __new__(cls, *args, **kwargs):
        if hasattr(cls, '_inst'):
            old_cls_inst = cls._inst
            delattr(cls, '_inst')
        else:
            old_cls_inst = None
        cls._to_cache = {}
        # checking if given argument is sqlintf object or existing id
        cls._input = args[0] if len(args) else None
        if not isinstance(cls._input, si.Input):
            keyid = kwargs.get('id', cls._input)
            if isinstance(keyid, int):
                for session in cls._check_in_cache(kind='keyid', loc=keyid):
                    cls._input = session.query(si.Input).filter_by(id=keyid).one()
            else:
                # gathering construction arguments
                wpargs, args, kwargs = initialize_args(args, kwargs, nargs=1)
                pipeline = kwargs.get('pipeline', wpargs.get('Pipeline', None))
                base, name = os.path.split(clean_path(kwargs.get('path', args[0])))
                # querying the database for existing row or create
                for session in cls._check_in_cache(kind='args', loc=(pipeline.pipeline_id, name)):
                    for retry in session.retrying_nested():
                        with retry:
                            this_nested = retry.retry_state.begin_nested()
                            cls._input = this_nested.session.query(si.Input).with_for_update(). \
                                filter_by(pipeline_id=pipeline.pipeline_id). \
                                filter_by(name=name).one_or_none()
                            if cls._input is None:
                                cls._input = si.Input(name=name,
                                                      rawspath=pipeline.input_root+'/'+name,
                                                      confpath=pipeline.config_root+'/'+name)
                                pipeline._pipeline.inputs.append(cls._input)
                                this_nested.commit()
                                if not os.path.isdir(cls._input.rawspath):
                                    os.mkdir(cls._input.rawspath)
                                cls._copy_data(base+'/'+name)
                                if not os.path.isdir(cls._input.confpath):
                                    os.mkdir(cls._input.confpath)
                            else:
                                this_nested.rollback()
                            retry.retry_state.commit()
        else:
            cls._sqlintf_instance_argument()
        # verifying if instance already exists and return
        wpipe_to_sqlintf_connection(cls, 'Input')
        # add instance to cache dataframe
        if cls._to_cache:
            cls._to_cache[CLASS_LOW] = cls._inst
            cls.__cache__.loc[len(cls.__cache__)] = cls._to_cache
            del cls._to_cache
        new_cls_inst = cls._inst
        delattr(cls, '_inst')
        if old_cls_inst is not None:
            cls._inst = old_cls_inst
        return new_cls_inst

    @maintain_cache
    # @_in_session()
    def __init__(self, *args, **kwargs):
        if not hasattr(self, '_targets_proxy'):
            self._targets_proxy = ChildrenProxy(self._input, 'targets', 'Target')
        if not hasattr(self, '_dpowner'):
            self._dpowner = self._input
        super(Input, self).__init__()
        self._verify_raws()

    @_in_session()
    def __repr__(self):
        cls = self.__class__.__name__
        description = ', '.join([(f"{prop}={getattr(self, prop)}") for prop in [KEYID_ATTR]+UNIQ_ATTRS])
        return f'{cls}({description})'

    @classmethod
    def select(cls, *args, **kwargs):
        """
        Returns a list of Input objects fulfilling the kwargs filter.

        Parameters
        ----------
        kwargs
            Refer to :class:`sqlintf.Input` for parameters.

        Returns
        -------
        out : list of Input object
            list of objects fulfilling the kwargs filter.
        """
        for session in si.begin_session():
            with session as session:
                cls._temp = session.query(si.Input).filter_by(**kwargs)
                for arg in args:
                    cls._temp = cls._temp.filter(arg)
                return list(map(cls, cls._temp.all()))

    @classmethod
    def _copy_data(cls, path):
        if hasattr(cls, '_input'):
            if hasattr(cls._input, 'rawspath'):
                if os.path.isfile(path):
                    shutil.copy2(path, cls._input.rawspath + '/')
                elif os.path.isdir(path):
                    for filepath in glob.glob(path+'/*'):
                        shutil.copy2(filepath, cls._input.rawspath + '/')

    def _verify_raws(self):
        for filename in glob.glob(self.rawspath+'/*'):
            if os.path.splitext(filename)[-1] == '.conf':
                self.make_config(filename)
                os.remove(filename)
            else:
                base, name = os.path.split(filename)
                self.dataproduct(filename=name, relativepath=base, group='raw')

    @property
    def parents(self):
        """
        :obj:`Pipeline`: Points to attribute self.pipeline.
        """
        return self.pipeline

    @property
    @_in_session()
    def name(self):
        """
        str: Name of the input.
        """
        self._session.refresh(self._input)
        return _query_return_and_update_cached_row(self, 'name')

    @name.setter
    @_in_session()
    def name(self, name):
        self._input.name = name
        _temp = _query_return_and_update_cached_row(self, 'name')
        self.update_timestamp()
        # self._input.timestamp = datetime.datetime.utcnow()
        # self._session.commit()

    @property
    @_in_session()
    def input_id(self):
        """
        int: Primary key id of the table row.
        """
        return self._input.id

    @property
    @_in_session()
    def rawspath(self):
        """
        str: Path to the input directory specific to raw data files.
        """
        return self._input.rawspath

    @property
    @_in_session()
    def confpath(self):
        """
        str: Path to the input directory specific to configuration files.
        """
        return self._input.confpath

    @property
    @_in_session()
    def pipeline_id(self):
        """
        int: Primary key id of the table row of parent pipeline.
        """
        return self._input.pipeline_id

    @property
    @_in_session()
    def pipeline(self):
        """
        :obj:`Pipeline`: Pipeline object corresponding to parent pipeline.
        """
        if hasattr(self._input.pipeline, '_wpipe_object'):
            return self._input.pipeline._wpipe_object
        else:
            from .Pipeline import Pipeline
            return Pipeline(self._input.pipeline)

    @property
    def targets(self):
        """
        :obj:`core.ChildrenProxy`: List of Target objects owned by the input.
        """
        return self._targets_proxy

    def target(self, *args, **kwargs):
        """
        Returns a target owned by the input.

        Parameters
        ----------
        kwargs
            Refer to :class:`Target` for parameters.

        Returns
        -------
        target : :obj:`Target`
            Target corresponding to given kwargs.
        """
        from .Target import Target
        return Target(self, *args, **kwargs)

    def make_config(self, config_file):
        """
        Associate given file to the input as a conf dataproduct.

        Parameters
        ----------
        config_file : str
            Path to configuration file.
        """
        config_file = clean_path(config_file)
        if config_file is not None:
            shutil.copy2(config_file, self.confpath)
            self.dataproduct(filename=os.path.split(config_file)[-1], relativepath=self.confpath, group='conf')

    def reset(self):
        """
        Reset the input.
        """
        self.targets.delete()

    def remove_data(self):
        """
        Remove pipeline's directories.
        """
        remove_path(self.confpath, self.rawspath)

    @maintain_cache
    def delete(self):
        """
        Delete corresponding row from the database.
        """
        self.reset()
        super(Input, self).delete(self.remove_data)
        self.__class__.__cache__ = self.__cache__[self.__cache__[CLASS_LOW] != self]
